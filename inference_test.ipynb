{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9f678e4-5432-4a29-b91b-24e099946156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AutoConfig, get_linear_schedule_with_warmup\n",
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684f30bc-fb28-42be-8235-241a15ac25b0",
   "metadata": {},
   "source": [
    "# Pipeline Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27f3f2d5-0cb2-4952-a279-2429ed21c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d103427-4a65-4fef-986a-1526582cde44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"snunlp/KR-FinBert-SC\", num_labels=3)\n",
    "model.eval()\n",
    "torch.save(model.state_dict(), f\"best_chkpt_origin.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42dc14d5-f36c-47c4-84a5-e727f98c69a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model1 = AutoModelForSequenceClassification.from_pretrained(\"snunlp/KR-FinBert-SC\", num_labels=3) \n",
    "checkpoint1 = torch.load(\"best_chkpt_origin.pt\") \n",
    "print(test_model1.load_state_dict(checkpoint1))\n",
    "test_model1.to(device) \n",
    "test_model1.eval() \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bd2298c-3139-4074-b80f-1c91255e9c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'neutral', 'score': 0.9998950958251953}]\n",
      "[{'label': 'neutral', 'score': 0.6948619484901428}]\n"
     ]
    }
   ],
   "source": [
    "my_pipeline = pipeline(\"sentiment-analysis\", model=test_model1, tokenizer=\"snunlp/KR-FinBert-SC\")\n",
    "print(my_pipeline(\"그러나 이 중개인은 주식에 대해 초과 추천을 했다.\"))\n",
    "print(my_pipeline(\"피스카는 영국 전역에서 지역사회 프로젝트를 수행할 예정이며 선정된 복구 프로젝트에 도움을 주는 데 관심이 있는 현지 자원봉사자들을 찾고 있다.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb4556f-f5ff-4eda-9d7d-ab498f0ee7a8",
   "metadata": {},
   "source": [
    "# Custom Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9132fa18-00f5-4c0c-bf72-a7459bdf2130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'negative', 1: 'neutral', 2: 'positive'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = my_pipeline.model.config.id2label\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd53066e-b9ee-40df-9527-5b723fbebdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "label: neutral, score:0.9998950958251953\n",
      "label: neutral, score:0.6948619484901428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_217/1357513801.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = nn.Softmax()(output.logits)\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"그러나 이 중개인은 주식에 대해 초과 추천을 했다.\", \"피스카는 영국 전역에서 지역사회 프로젝트를 수행할 예정이며 선정된 복구 프로젝트에 도움을 주는 데 관심이 있는 현지 자원봉사자들을 찾고 있다.\"]\n",
    "\n",
    "device = torch.device(\"cpu\") \n",
    "test_model1 = AutoModelForSequenceClassification.from_pretrained(\"snunlp/KR-FinBert-SC\", num_labels=3) \n",
    "checkpoint1 = torch.load(\"best_chkpt_origin.pt\") \n",
    "print(test_model1.load_state_dict(checkpoint1))\n",
    "test_model1.to(device) \n",
    "test_model1.eval() \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"snunlp/KR-FinBert-SC\")\n",
    "\n",
    "for sentence in sentences:\n",
    "    encoded_input = tokenizer(sentence, return_tensors=\"pt\") \n",
    "    with torch.no_grad():\n",
    "        output = test_model1(**encoded_input) \n",
    "        probs = nn.Softmax()(output.logits)  \n",
    "        score = torch.max(probs, dim=1)\n",
    "        print(f\"label: {labels[score.indices.item()]}, score:{score.values.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f7db4b-9290-44af-87dd-848ec0d59237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
